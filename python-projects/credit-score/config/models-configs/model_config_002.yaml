hidden_layers:
  - 256
  - 128
  - 64
  - 32
activation_functions:
  - leaky_relu
  - leaky_relu
  - leaky_relu
  - leaky_relu
dropout_rate: 0.4
learning_rate: 0.0001
epochs: 200
batch_size: 128
